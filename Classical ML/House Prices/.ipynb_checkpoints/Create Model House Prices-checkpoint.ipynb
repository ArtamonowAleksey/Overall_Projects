{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb7315db-48ba-47f2-95dd-70ac0fa01d7f",
   "metadata": {},
   "source": [
    "### Вопросы\n",
    "\n",
    "- Пайплайн создания модели в реальной жизни,откуда берем данные(Hdoop,БД итд)\n",
    "- [Преобразователь данных которые идут на вход во время деплоя ,как это все хранится(классы,функции) best practice](#1).\n",
    "    - Использовать встроенные Imputer ,если использовать самописные то как его потом применить\n",
    "    - Чистота кода\n",
    "- [Хранение различных артефактов](#2).\n",
    "- [Используется ли вообще декодирование категориальных признаков и декодирование в числа после нормолизации](#3).\n",
    "- [Пайплайн подбора модели ,нужно ли автоматизировать этот процесс в реальной жизни](#4).\n",
    "- Частота переобучения модели ,подходы к конвейеру обучения/переобучения\n",
    "\n",
    "\n",
    "<a id='0'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e552ebb4-463c-4080-a058-026eb9131f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score,KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Lasso,Ridge\n",
    "\n",
    "#Список моделей которые будем использовать\n",
    "\n",
    "#Модели регрессии\n",
    "#Gradient Boosting Regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#Elastic Net Regression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "#Stochastic Gradient Descent Regression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "#Support Vector Machine\n",
    "from sklearn.svm import SVR\n",
    "#Bayesian Ridge Regression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "#CatBoost Regressor\n",
    "from catboost import CatBoostRegressor\n",
    "#Kernel Ridge Regression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "#Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#Ridge and Lasso regression\n",
    "#XGBoost Regressor\n",
    "from xgboost import XGBRegressor\n",
    "#LGBM Regressor\n",
    "#from lightgbm import LGBMRegressor\n",
    "\n",
    "# Подбор гиперпараметров\n",
    "\n",
    "import optuna\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2e64b-9fa3-41fb-9f37-72392b243848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ставим кол-во выводимых строк и столбцов \n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "#Отключаем предупреждения\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a686ac83-e207-4c0a-9080-f34f53d25803",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c821912-4825-49d8-b28d-76e49c63f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загружаем данные\n",
    "\n",
    "train_data = 'train.csv'\n",
    "test_data = 'test.csv'\n",
    "\n",
    "with open(train_data) as train:\n",
    "    train_df = pd.read_csv(train)\n",
    "    \n",
    "with open(test_data) as test:\n",
    "    test_df = pd.read_csv(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ab8a5a-5a09-48c6-aa3f-4ca2564dee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy = train_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3b30c-f045-471d-b783-5b6592934f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf77bed7-3832-4b68-a4a4-6e7717e1c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f4c2e5-e6e3-44cc-aac3-895360d8a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверка на дубли\n",
    "\n",
    "train_df_copy[train_df_copy.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5802b-5eb5-40d2-a146-a46f1f79f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удаляем дубли\n",
    "\n",
    "train_df_copy.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edf3518-5de1-4a96-8cce-7c6645d50318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Описание данных \n",
    "\n",
    "train_df_copy.describe().loc[['min', 'max', 'mean', 'std']].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b34618-55cb-419f-a56b-41bdd657307b",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b6cd94-6cdd-4f35-8c6c-da58b53dce3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функции для создания таблицы по пропускам и визуализации фичей с пропусками\n",
    "\n",
    "def missings(data_frame,missings_percent):\n",
    "\n",
    "    total = data_frame.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (data_frame.isnull().sum()/train_df.isnull().count()*100).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    missing_data = missing_data[(missing_data['Percent']>missings_percent)]\n",
    "    \n",
    "    return missing_data\n",
    "    \n",
    "def missings_bar_vizualisation(data_frame,missings_percent):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        total = data_frame.isnull().sum().sort_values(ascending=False)\n",
    "        percent = (data_frame.isnull().sum()/train_df.isnull().count()*100).sort_values(ascending=False)\n",
    "        missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "        missing_data = missing_data[(missing_data['Percent']>missings_percent)]\n",
    "    \n",
    "        #plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "        sns.barplot(x=missing_data.index,y=missing_data['Percent'],data = missing_data)\n",
    "        plt.xticks(rotation=70)\n",
    "        plt.show()\n",
    "    \n",
    "    except ValueError:\n",
    "        \n",
    "        print('No missings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987b4f5-6b51-4000-81d4-70539c781472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missings(train_df_copy,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b87ef-fea1-450a-9a1f-480cd680901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "missings_bar_vizualisation(train_df_copy,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf9eee6-31fe-4882-98d9-5f03f9e86bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Дропним у кого больше percent пропусков\n",
    "\n",
    "percent = 60\n",
    "\n",
    "#Записываем таблицу с % пропусков\n",
    "\n",
    "missings_table = missings(train_df_copy,percent)\n",
    "\n",
    "#Получаем список колонок на удаление\n",
    "\n",
    "for_drop = missings_table.index.to_list()\n",
    "\n",
    "#Удаляем колонки\n",
    "after_drops = train_df_copy.drop(columns = for_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811b0bfe-100a-4eac-93f7-1665027ed9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57956346-3039-4378-8b20-54b452ef3151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверяем что удалились колонки с процентом пропусков больше чем percent\n",
    "\n",
    "missings_bar_vizualisation(after_drops,percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae1713-368e-4602-a2e6-85b7b7140ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_drops.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befeff2d-069c-4dde-9da3-2b6a4b37d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Смотрим на оставшуюся таблицу\n",
    "\n",
    "after_drops.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b42b4d9-c22a-4b98-b421-0091eb9bd03e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Дропним поле Id за ненадобностью\n",
    "\n",
    "after_drops.drop(columns = 'Id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0736fc44-f94d-4d21-b4dd-d80e1384fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Список полей у которых есть пропуски\n",
    "\n",
    "list_of_missing_columns = missings(after_drops,0).index.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647196b7-c2b9-443f-a244-09a8f11d344a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_of_missing_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a1771-6f23-4933-98a8-176e4e28d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "missings_bar_vizualisation(after_drops,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc2e8ce-61d5-4e02-b323-359765c848ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "after_drops.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b5a561-09c6-4f48-8372-ee7dfbd13968",
   "metadata": {},
   "source": [
    "#### Преобразователь данных которые идут на вход во время деплоя ,как это все хранится(классы,функции) best practice\n",
    "<a id='1'></a>\n",
    "\n",
    "[Вопросы](#0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ed887-40de-426a-91a8-f6432540517e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Заполним пропуски по всем переменным. Для числовых ставим median() для категориальных \"None\"\n",
    "#Стратегий заполнения пропусков может быть много более продвинутая это заполнение относительно целевой переменной\n",
    "\n",
    "#В реальных данных пропущенными могут быть абсолютно любые поля поэтому заполнение производим по всем полям которые есть в датафрейме \n",
    "#после удаления ненужных колонок даже если там нет пропусков\n",
    "\n",
    "#Float и int можно объединить в один if\n",
    "\n",
    "unique_types = after_drops.dtypes.unique()\n",
    "\n",
    "#Для простоты заполним медианным значением\n",
    "\n",
    "for typ in unique_types:\n",
    "    \n",
    "    if typ == 'object':\n",
    "        \n",
    "        object_columns = after_drops.select_dtypes(include = ['object']).columns.to_list()\n",
    "        after_drops[object_columns] = after_drops[object_columns].fillna('None')\n",
    "    \n",
    "    elif typ == 'float64':\n",
    "        \n",
    "        float_columns = after_drops.select_dtypes(include = ['float64']).columns.to_list()\n",
    "        after_drops[float_columns] = after_drops[float_columns].fillna(after_drops[float_columns].median())\n",
    "\n",
    "    \n",
    "    elif typ == 'int64':\n",
    "        \n",
    "        int_columns = after_drops.select_dtypes(include = ['int64']).columns.to_list()\n",
    "        after_drops[int_columns] = after_drops[int_columns].fillna(after_drops[int_columns].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c55b87-1f92-4f1c-ad78-f1e9d28559d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Артефакты по заполнению пропусков для числовых переменных\n",
    "\n",
    "after_drops[float_columns].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568f45ad-4527-4fad-a836-498f7caa7bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "after_drops[int_columns].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea15191-c0df-4d2a-a4ae-9826c652429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_float_artefacts = pd.concat([after_drops[float_columns].median(),after_drops[int_columns].median()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e12a79-ff90-4780-b35a-d705f7cc8a79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "int_float_artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6968ac6-bba0-40ec-aeea-e4f7d0b9702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Еще раз проверяем что все заполнилось \n",
    "\n",
    "missings_bar_vizualisation(after_drops,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d47a4c-0db8-4bb9-9a62-c415006204b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для визуализации hist plot ,boxplot,countplot и Scatter plot для всех признаков\n",
    "\n",
    "def overall_viz(data_frame,cols,cell):\n",
    "\n",
    "    heart_CAT = data_frame.columns.to_list()\n",
    "\n",
    "#  Categorical Data\n",
    "\n",
    "    b = cols  # number of columns\n",
    "    a = math.ceil(len(heart_CAT)/b)*3  # number of rows\n",
    "    c = 1  # initialize plot counter\n",
    "\n",
    "    fig = plt.figure(figsize = (20,200))\n",
    "\n",
    "\n",
    "\n",
    "    for i in heart_CAT:\n",
    "        \n",
    "        if data_frame[i].dtype in ['float64','int64']:\n",
    "            \n",
    "            plt.subplot(a, b, c)\n",
    "            plt.xlabel(i)\n",
    "            sns.boxplot(data = data_frame, x = i)\n",
    "            c = c + 1\n",
    "    \n",
    "            plt.subplot(a, b, c)\n",
    "            plt.xlabel(i)\n",
    "            sns.histplot(data = data_frame, x = i)\n",
    "            c = c + 1\n",
    "            \n",
    "            plt.subplot(a, b, c)\n",
    "            plt.xlabel(i)\n",
    "            sns.scatterplot(data=data_frame, x=cell, y=i)\n",
    "            c = c + 1\n",
    "        \n",
    "        elif data_frame[i].dtype in ['object']:\n",
    "            \n",
    "            plt.subplot(a, b, c)\n",
    "            plt.xlabel(i)\n",
    "            sns.countplot(data = data_frame, x = i)\n",
    "            c = c + 1\n",
    "            \n",
    "            plt.subplot(a, b, c)\n",
    "            plt.xlabel(i)\n",
    "            sns.histplot(data = data_frame, x = i)\n",
    "            c = c + 1\n",
    "            \n",
    "            plt.subplot(a, b, c)\n",
    "            plt.xlabel(i)\n",
    "            sns.scatterplot(data=data_frame, x=cell, y=i)\n",
    "            c = c + 1\n",
    "        \n",
    "        \n",
    "#QQ Plot    \n",
    "#    plt.subplot(a, b, c)\n",
    "#    plt.xlabel(i)\n",
    "#    pplot(data = after_drops_numeric,x = i,kind='qq')\n",
    "#    c = c + 1\n",
    "\n",
    "#fig.tight_layout(h_pad=2,w_pad=2)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab6da50-3380-4042-9c59-0bc3c58dcc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_viz(after_drops,3,\"SalePrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448afc02-f60e-46b3-9e4e-0e8a87b568a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохраним список категориальных признаков\n",
    "\n",
    "categorical_features = after_drops.select_dtypes(include=['object']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba71c991-8b10-4acb-a7c4-6e38f7e6c6a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2505850d-6e5c-435a-a3e9-1d0fff05da82",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3276747912.py, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 28\u001b[0;36m\u001b[0m\n\u001b[0;31m    <a id='3'></a>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Преобразование категориальных признаков\n",
    "\n",
    "#Lable encoding\n",
    "\n",
    "\n",
    "cols = after_drops.select_dtypes(include = ['object']).columns.to_list()\n",
    "\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "\n",
    "transform_df = pd.DataFrame()\n",
    "\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(after_drops[c].values)) \n",
    "    after_drops[c] = lbl.transform(list(after_drops[c].values))\n",
    "\n",
    "#Создадим словарь для последующего декодирования\n",
    "    \n",
    "    keys = lbl.classes_\n",
    "    values = lbl.transform(lbl.classes_)\n",
    "    transform = pd.DataFrame(zip(keys, values),columns = ['name','transform_value'])\n",
    "    transform['feature_name'] = c\n",
    "    transform_df = pd.concat([transform,transform_df])\n",
    "\n",
    "# shape        \n",
    "#print('Shape all_data: {}'.format(after_drops.shape),)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76579032-b665-4f77-a8a0-54102df27220",
   "metadata": {},
   "source": [
    "#### Используется ли вообще декодирование категориальных признаков и декодирование в числа после нормолизации\n",
    "\n",
    "<a id='3'></a>\n",
    "\n",
    "[Вопросы](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac9c74-1a7b-42ef-b568-f91c078a5fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Можно увидеть, что None декодируется например 4, хотя возможно что 0 было бы более подходящее значение\n",
    "#Артефакт\n",
    "\n",
    "transform_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d496628b-22da-4103-9661-be49093d9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверим что все преобразовалось\n",
    "\n",
    "after_drops.select_dtypes(include = ['object']).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af48fa-886d-4af1-83d6-e76b4faef1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_drops.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cad01b-e57a-4b3a-8e79-0eba8336fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_viz(after_drops,3,\"SalePrice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad8e20f-e453-4904-b34a-c33689cc776f",
   "metadata": {},
   "source": [
    "### К текущему этапу наш датафрейм очищен от больших пропусков и преобразованны категориальные переменные\n",
    "#### Преобразование категориальных переменных можно было бы и опустить если мы будем использовать catboost, которые принимает на вход категориальные переменные.\n",
    "#### Так же можно было бы детальнее поработать с заполнением пропусков для категориальных переменных а именно заполнить их не None а более умным способом.\n",
    "#### Обратное декодирование было сделано с целью тренеровки оно так же скорее всего не понадобится в дальнейшем"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b423ebe0-fb0c-4e4a-8f58-581a5aeb8612",
   "metadata": {},
   "source": [
    "#### Хранение различных артефактов\n",
    "\n",
    "<a id='2'></a>\n",
    "\n",
    "[Вопросы](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d3581-aaae-4f12-92f9-267e1c0b6365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Корреляция относительно целевой переменной\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "after_drops.corr()['SalePrice'].sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e5c84b-139e-4270-9f94-8971aededd62",
   "metadata": {},
   "source": [
    "### Model train an selection\n",
    "\n",
    "<a id='4'></a>\n",
    "\n",
    "[Вопросы](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98301b0c-3427-4820-8b44-6295b97fe9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разделим набор данных и целевую переменную\n",
    "\n",
    "X_train = after_drops.loc[:,:'SaleCondition']\n",
    "Y_train = after_drops['SalePrice']\n",
    "\n",
    "#Нормализация данных\n",
    "\n",
    "#В дальнейшем мы не будем использовать нормализацию но пусть будет тут\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "x_minmax = scaler.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494a2057-21de-45be-8dee-c6bfbcf3a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмем сразу несколько моделей и сделаем поиск по сетке\n",
    "#Параметры по моделям Регрессоров(Надо засунуть в yaml)\n",
    "\n",
    "catboost_params = {\n",
    "    'iterations': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'depth': [3, 6,10]\n",
    "         }\n",
    "\n",
    "lasso_params = {\n",
    "    'alpha':[0.01,0.1,0,10,100,200,300,500]\n",
    "        }\n",
    "\n",
    "ridge_params = {'alpha':[200, 230, 250,265, 270, 275, 290, 300, 500]}\n",
    "\n",
    "xgb_params ={\"learning_rate\": (0.05, 0.10, 0.15),\n",
    "                        \"max_depth\": [ 3, 4, 5, 6, 8],\n",
    "                        \"min_child_weight\": [ 1, 3, 5, 7],\n",
    "                        \"gamma\":[ 0.0, 0.1, 0.2],\n",
    "                        \"colsample_bytree\":[ 0.3, 0.4]\n",
    "            }\n",
    "\n",
    "DecisionTreeRegressor_params = [\n",
    "    {'max_depth': [3, 5, 10], \n",
    "     'max_features': [3, 4, 5]},\n",
    "    {'random_state': [0, 1, 2, 3, 4], \n",
    "     'min_samples_split': [2, 3, 4]}    \n",
    "]\n",
    "\n",
    "ElasticNet_params = [\n",
    "        {'alpha': [.0004, .0005], 'l1_ratio': [.5, .8, 1]}\n",
    "]\n",
    "\n",
    "#Словарь модель:параметры\n",
    "\n",
    "models_dict = {'models':\n",
    "               [CatBoostRegressor(),\n",
    "                Lasso(),\n",
    "                XGBRegressor(),\n",
    "                Ridge(),\n",
    "                DecisionTreeRegressor(),\n",
    "                ElasticNet()\n",
    "               ],\n",
    "               \n",
    "               'params':[catboost_params,\n",
    "                         lasso_params,\n",
    "                         xgb_params,\n",
    "                         ridge_params,\n",
    "                         DecisionTreeRegressor_params,\n",
    "                         ElasticNet_params\n",
    "                        ]\n",
    "              }\n",
    "\n",
    "error = 'r2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12a4f43-0780-45b7-8296-2003131d93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "####Блок по моделям\n",
    "\n",
    "def models_cyckle(X_train,Y_train,folds,error):\n",
    "\n",
    "    models_report = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(models_dict['models'])):\n",
    "        \n",
    "        \n",
    "          \n",
    "        grid_search = GridSearchCV(models_dict['models'][i], param_grid=models_dict['params'][i], cv=folds, scoring=error, n_jobs=-1)\n",
    "        grid_search.fit(X_train, Y_train)\n",
    "    \n",
    "        best_model = pd.DataFrame(grid_search.cv_results_).sort_values(by='rank_test_score').head(1)\n",
    "        best_model['model_name'] = str(models_dict['models'][i])\n",
    "        models_report = pd.concat([models_report,best_model])\n",
    "    \n",
    "    return models_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb250b-80b7-4c68-9985-76e396cf62ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = models_cyckle(X_train,Y_train,folds,error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff962e2-8e32-4b05-b48d-7892f391afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.loc[:,:'model_name'].sort_values(by='mean_test_score',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1caa944-4edd-4fae-9812-60d816179a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Получаем что лучше всего с задачей справился XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa8088-fb1a-4af9-856b-629574acb747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Теперь самое интересное.\n",
    "#Надо взять наш тестовый датасет и произвести над ним все манипуляции, которые производили с train.\n",
    "#Заполнить пропуски,закодировать категориальные переменные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a4ded6-521b-4a03-8326-2e556913fac5",
   "metadata": {},
   "source": [
    "#### Артефакты к данному моменту, которые нужно будет потом преобразовать в python код\n",
    "##### Список полей которые мы использовали при обучении(мы не отбрасывали ни какие признаки на основании аналитического исследования, а отбрасывали только пустые)\n",
    "##### Заполнение пропусков\n",
    "##### Кодирование категориальных переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b213c112-227b-4109-af29-905da8f0bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выбираем XGBRegressor с такими параметрами\n",
    "\n",
    "#{'colsample_bytree': 0.3, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 1}\n",
    "\n",
    "xgb_params ={\"learning_rate\": 0.1,\n",
    "                        \"max_depth\": 4,\n",
    "                        \"min_child_weight\":1,\n",
    "                        \"gamma\":0.1,\n",
    "                        \"colsample_bytree\":0.3\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef32440-1595-47fb-b8b1-89398520956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Передаем в модель наши параметры\n",
    "\n",
    "model = XGBRegressor(**xgb_params).fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7f7664-b0d1-4613-9f35-1c8c3bcdb8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним нашу модель\n",
    "import pickle\n",
    "\n",
    "with open(\"XGBRegressor.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae09b5-30a4-4780-a653-45d801e408de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пишем класс для преобразования пропусков которы потом преобразуем в python файл\n",
    "\n",
    "передаем значения или датафрейм в функцию\n",
    "оставляем только нужные колонки которые использовали при обучении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a1c3c5-7ffd-4067-901d-b0650fdebf2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "used_columns = after_drops.loc[:,:'SaleCondition'].columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15469d34-3e0b-4103-ab96-95cfb9a42250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df[used_columns].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f706cd6-bb30-4566-8468-b72b83e6f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Imputer(dataframe,used_columns):\n",
    "\n",
    "    #Оставляем поля которые использовали при обучении\n",
    "    \n",
    "    used_df = dataframe[used_columns]\n",
    "\n",
    "    #Заменяем пропуски с помощью артефактов полученных на тренеровочном датасете\n",
    "\n",
    "    unique_types = used_df.dtypes.unique()\n",
    "\n",
    "#Для простоты заполним медианным значением\n",
    "\n",
    "    for typ in unique_types:\n",
    "    \n",
    "        if typ == 'object':\n",
    "        \n",
    "            object_columns = used_df.select_dtypes(include = ['object']).columns.to_list()\n",
    "            used_df[object_columns] = used_df[object_columns].fillna('None')\n",
    "\n",
    "        elif typ != 'object':\n",
    "            \n",
    "            non_object_columns = used_df.select_dtypes(exclude = ['object']).columns.to_list()\n",
    "            \n",
    "            for i in non_object_columns:\n",
    "                \n",
    "                used_df[i] = used_df[i].map(transform_df[['name','transform_value']][transform_df['feature_name'] == i].set_index('name').to_dict()['transform_value'])\n",
    "            \n",
    "            used_df.map(int_float_artefacts)\n",
    "    \n",
    "        \n",
    "\n",
    "    return used_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb7336b-d7f0-4f57-adf6-7a2ef679a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_float_artefacts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ee8e73-a757-4c2c-bcfb-e0a1f44aaf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_float_artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f03a03-a568-476e-a744-8075dd6fd246",
   "metadata": {},
   "outputs": [],
   "source": [
    "Imputer(train_df,used_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc3e069-4091-44d9-ab9e-6f1fbf0ead91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Артефакты по заполнению пропусков медианным значением\n",
    "int_float_artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8302ea69-9e0e-41a5-bfd1-83b4b308f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразуем пропуски\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1b248c-38e9-4c7c-b4ff-e9f905916848",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_types = after_drops.dtypes.unique()\n",
    "\n",
    "#Для простоты заполним медианным значением\n",
    "\n",
    "for typ in unique_types:\n",
    "    \n",
    "    if typ == 'object':\n",
    "        \n",
    "        object_columns = after_drops.select_dtypes(include = ['object']).columns.to_list()\n",
    "        after_drops[object_columns] = after_drops[object_columns].fillna('None')\n",
    "    \n",
    "    elif typ == 'float64':\n",
    "        \n",
    "        float_columns = after_drops.select_dtypes(include = ['float64']).columns.to_list()\n",
    "        after_drops[float_columns] = after_drops[float_columns].fillna(after_drops[float_columns].median())\n",
    "\n",
    "    \n",
    "    elif typ == 'int64':\n",
    "        \n",
    "        int_columns = after_drops.select_dtypes(include = ['int64']).columns.to_list()\n",
    "        after_drops[int_columns] = after_drops[int_columns].fillna(after_drops[int_columns].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be5f36-28fa-4c65-a88b-91801ae289f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8a4860-7423-46a7-b32f-4d2f1fed4891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f526fe7-ef72-4854-87d3-d7bc8092e04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89026072-11ff-4ed6-b3b6-86e5af05ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Берем только колонки на которых обучались\n",
    "\n",
    "test_df_2 = test_df[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a2d66a-52c6-483a-b2d8-ea1a279f7d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Наши артефакты\n",
    "\n",
    "#Перевод категориальных переменных в числовые из LabelEncoder\n",
    "transform_df \n",
    "\n",
    "#Заполнение пропусков в числовых переменных\n",
    "\n",
    "after_drops[float_columns].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec8ddc4-d0a6-4062-a81d-5d08725d0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Список полей у которых есть пропуски\n",
    "\n",
    "list_of_missing_columns_2 = missings(test_df_2,0).index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af961e79-4d7a-4199-82f2-155a69e9a6d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_of_missing_columns_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212cf196-91ea-4063-ae58-cb0ce021c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заполним пропуски по всем переменным. Для числовых ставим median() для категориальных \"None\"\n",
    "\n",
    "unique_types = test_df_2[list_of_missing_columns_2].dtypes.unique()\n",
    "\n",
    "\n",
    "for typ in unique_types:\n",
    "    \n",
    "    if typ == 'object':\n",
    "        \n",
    "        object_columns = test_df_2[list_of_missing_columns_2].select_dtypes(include = ['object']).columns.to_list()\n",
    "        test_df_2[object_columns] = test_df_2[object_columns].fillna('None')\n",
    "    \n",
    "    elif typ == 'float64':\n",
    "        \n",
    "        float_columns = test_df_2[list_of_missing_columns_2].select_dtypes(include = ['float64']).columns.to_list()\n",
    "        test_df_2[float_columns] = test_df_2[float_columns].fillna(after_drops[float_columns].median())\n",
    "\n",
    "    \n",
    "    elif typ == 'int64':\n",
    "        \n",
    "        int_columns = test_df_2[list_of_missing_columns_2].select_dtypes(include = ['int64']).columns.to_list()\n",
    "        test_df_2[int_columns] = test_df_2[int_columns].fillna(after_drops[int_columns].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c677fc-7965-4d63-87cd-a0ec79eaf902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Еще раз проверяем что все заполнилось \n",
    "\n",
    "missings_bar_vizualisation(test_df_2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caca2b2-2734-4db6-83f0-82a13ee41a1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea81553e-2918-4aed-bf1d-34840aa7f0bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Декодирование категориальных переменных\n",
    "transform_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46013e3d-89df-40ed-9358-2dce20ecd787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Само декодирование\n",
    "\n",
    "obj_col = test_df_2.select_dtypes('object').columns.to_list()\n",
    "for i in obj_col:\n",
    "    test_df_2[i] = test_df_2[i].map(transform_df[['name','transform_value']][transform_df['feature_name'] == i].set_index('name').to_dict()['transform_value'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a2edb0-cd20-4ef1-a2a3-4f6e25a9ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f94a5-5508-42c0-a0d8-0467d10c8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_2[obj_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935e047a-1cc8-4f25-a1b7-784e364b3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_drops.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da500f04-e57b-49c4-aea7-56e70257ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Делаем предсказание\n",
    "\n",
    "prediction = model.predict(test_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4127e86-c54e-4832-8088-1429685be134",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9210fc88-0ea2-4d3a-9af5-5e821ccc6635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8028a49e-833b-4519-9e66-c80015a54ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['Id'] = test_df['Id']\n",
    "sub['SalePrice'] = prediction\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe3bbbd-bedb-4bb1-ba57-4c4a03a707ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa488d5-b703-479b-b11a-a3c681fde701",
   "metadata": {},
   "source": [
    "#### Выводы:\n",
    "\n",
    "- 1.Не поработал с аномалиями\n",
    "- 2.Сложная система декодирования - но я хотел попробовать ее сделать.\n",
    "- 3.Нету ФичаИнжениринга\n",
    "- 4.Надо упростить код - убрать функции всякие чтоб стало прозрачнее\n",
    "- 5.Заполнение пропусков - можно использовать что то более интересное KNNImputer например\n",
    "- 6.Декодирование - можно посмотреть другие подходы\n",
    "- 7.Параметры моделей можно убрать в Yaml или ini файл\n",
    "- 8.Для большого числа экспериментов когда хочется попробовать разные импутеры и кодировщики надо использовать какой-то автоматизированный подход Airflow,MLFlow,Hydra,Piplines\n",
    "- 9.Вообще не читал описание данных.\n",
    "- 10.Разобраться с метриками\n",
    "- 11.Для CatBoost не обязательно делать кодирование\n",
    "- 12.Не использовал нормализацию\n",
    "- 13.Не проверил как прошло декодирование\n",
    "- 14.Попробовать AutoML\n",
    "- 15.Попробовать подбор параметров модели через Optuna\n",
    "- 16.Использовать готовые фреймворки для построения графиков\n",
    "- 17.PSI для проверки стабильности фич во времени\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c336df43-4751-498d-b19b-10c8bafa3290",
   "metadata": {},
   "source": [
    "- 15.Попробовать подбор параметров модели через Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7149c-75b8-4f71-a00d-fad436a92162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0f723-0784-4dd1-945d-82cac82a92da",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(study_name=\"my_first_study\", direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0077b6bd-2c72-4091-992a-cbe3c079ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params ={\"learning_rate\": (0.05, 0.10, 0.15),\n",
    "                        \"max_depth\": [ 3, 4, 5, 6, 8],\n",
    "                        \"min_child_weight\": [ 1, 3, 5, 7],\n",
    "                        \"gamma\":[ 0.0, 0.1, 0.2],\n",
    "                        \"colsample_bytree\":[ 0.3, 0.4]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d586f980-4bef-4230-afd8-3b39ec9142c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_params = {'alpha':[200, 230, 250,265, 270, 275, 290, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6596215-5725-47b0-a302-e63f462b4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "def objective(trial):\n",
    "    # предложение гиперпараметров\n",
    "    alpha = trial.suggest_float('alpha', 1e-10, 1.0, log=True)\n",
    "\n",
    "    # Модель\n",
    "    model = Ridge(alpha=alpha)\n",
    "\n",
    "    # предсказание и вычисление MSE\n",
    "    model.fit(X_train, Y_train)\n",
    "    error = cross_val_score(model, X_train, Y_train, n_jobs=-1, cv=folds,scoring = 'r2')\n",
    "    #mse = mean_squared_error(y_valid, y_pred)\n",
    "    \n",
    "    return error\n",
    "\n",
    "study = optuna.create_study(directions=['maximize'])\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"Error\":)\n",
    "print(\"  Values: \", trial.values)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9350d318-7253-40ee-9b24-c631f151827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {'models':\n",
    "               [\n",
    "                Ridge()\n",
    "               ],\n",
    "               \n",
    "               'params':[\n",
    "                         ridge_params\n",
    "                         \n",
    "                        ]\n",
    "              }\n",
    "\n",
    "error = 'r2'\n",
    "def models_cyckle(X_train,Y_train,folds,error):\n",
    "\n",
    "    models_report = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(models_dict['models'])):\n",
    "        \n",
    "        \n",
    "          \n",
    "        grid_search = GridSearchCV(models_dict['models'][i], param_grid=models_dict['params'][i], cv=folds, scoring=error, n_jobs=-1)\n",
    "        grid_search.fit(X_train, Y_train)\n",
    "    \n",
    "        best_model = pd.DataFrame(grid_search.cv_results_).sort_values(by='rank_test_score').head(1)\n",
    "        best_model['model_name'] = str(models_dict['models'][i])\n",
    "        models_report = pd.concat([models_report,best_model])\n",
    "    \n",
    "    return models_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a0b18-e1be-424f-8e8f-fb75643fe624",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = trial.suggest_float('alpha', 1e-10, 1.0, log=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6425e0b5-ccbe-4481-9f7b-a77c5cfeac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
